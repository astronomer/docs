import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

After you successfully deploy your code to Astro, you need to shift your workloads from your source Airflow environment to Astro on a DAG-by-DAG basis. 

Depending on how your workloads are set up, Astronomer recommends letting owners of your DAGs determine the order that you should migrate and test their DAGs.

You can complete the following steps in the next few days or weeks. Provide updates to your Astronomer Data Engineer as they continue to assist you through the process and any solve any difficulties that arise. 

Continue to validate and cut over your DAGs until you have fully migrated your source Airflow instance. After you have finished migrating from your source Airflow environment, repeat the complete migration process for any other Airflow instances in your source Airflow environment. 

#### Confirm connections and variables

In the Airflow UI for your Deployment, [test the connections](https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html#testing-connections) that you migrated from your source Airflow environment. 

Additionally, spot-check any Airflow variables by checking their values in **Admin** > **Variables**.

#### Test and Validate DAGs in Astro

To create a strategy for testing DAGs, determine which of your DAGs need the most care when running and testing them.

If your DAG workflow is idempotent and can run twice or more without negative effects, you can run and test these DAGs with minimal risk. 

If your DAG workflow is non-idempotent and can become invalid you rerun it, you should test the DAG with more caution and downtime. 

#### Cut over DAGs to Astro using Starship

Starship includes features for simultaneously pausing DAGs in your source Airflow environment and starting them on Astro. This allows you to cut over your production workflows without downtime. 

<Tabs>
<TabItem value="plugin" label="Starship Plugin" default>

For each DAG in your Astro Deployment:

1. Confirm that the DAG ID in your Deployment is the same as the DAG ID in your source Airflow environment.

2. In the Airflow UI for your source Airflow environment, go to **Astronomer** > **Migration Tool ðŸš€**.

2. Click **DAGs cutover**. In the table that appears, click the Pause icon in the **Local** column for the DAG you're cutting over. 

3. Click Start icon in the **Remote** column for the DAG you're cutting over. 

4. After completing this cutover, the Start and Pause icons switch. If there is an issue after cutting over, click the **Remote** pause button and then the **Local** start button to move your workflow back to your source Airflow environment. 

</TabItem>
<TabItem value="operator" label="Starship Operator">
The Starship Operator does not contain cut-over functionality.

To cut over a DAG, pause the DAG in the source Airflow and unpause the DAG in Astro. Keep both Airflow environments open as you test and ensure that the cutover was successful.

</TabItem>
</Tabs>

### Optimize Deployment resource usage

#### Monitor analytics

As you cut over DAGs, view your [Deployment metrics](deployment-metrics.md) page to get a sense of how many resources your Deployment is using. You can read more about this page in the [Deployment Metrics](deployment-metrics.md). Use this information to adjust your worker queues and resource usage accordingly. 

#### Modify instance types or use worker queues

If your current worker type doesn't have the right combination of resources for your workflows, see [Manage Worker Types](modify-cluster.md#manage-worker-types) to learn about adding additional worker types to your cluster.

You can additionally configure [worker queues](configure-worker-queues.md) to assign each of your tasks to different worker instance types. View your [Deployment metrics](deployment-metrics.md) help you determine what changes are required. 

#### Enable DAG-only deploys

The DAG-only deployment mechanism can make deploys faster in cases where you haven't modified your `Dockerfile`, `requirements.txt`, or `packages.txt` files. To enable DAG-only deploys, see [Deploy DAGs only](deploy-code.md#deploy-dags-only).
