---
sidebar_label: 'Migrate to Astro from GCC'
title: 'Migrating to Astro from GCC'
id: migrate-gcc
description: Get started on Astro by migrating your Airflow code from Google Cloud Composer (GCC).
---

import Intro from './migration-partials/intro.mdx';
import Prereq from './migration-partials/prereqs.mdx';
import Requirements from './migration-partials/requirements.mdx';
import Starship from './migration-partials/starship.mdx';
import Usage from './migration-partials/starship_usage.mdx';
import Workspaces from './migration-partials/workspaces.mdx';
import Deployments from './migration-partials/deployments.mdx';
import DAGs from './migration-partials/directory_setup.mdx';
import RuntimeVersionInfo from './migration-partials/runtime_version_info.mdx'


This is where you'll find instructions for migrating to Astro from another managed Airflow environment. This guide will
cover migrating an Airflow Instance from [Google Cloud Composer (GCC)](https://cloud.google.com/composer/docs/concepts/overview)

<Intro />

## Prerequisites

<Prereq />

### Requirements

<Requirements />

You can additionally utilize `gcloud` CLI to expedite some steps in this guide.


## Prepare Source and Setup Astro Airflow

### Step 1: Install Astronomer Starship
<Starship />

#### Starship Compatability Matrix

| Source Airflow      | Starship Plugin | Starship Operator |
|---------------------|-----------------|-------------------|
| Airflow 1.x         | ❌               | ❌                 |
| Cloud Composer 1 - Airflow 2.x |                 | ✔️️               |
| Cloud Composer 2 - Airflow 2.x | ✔️️             |                   |

#### Installation

To install Starship to your Cloud Composer 1 or Cloud Composer 2 instance, you'll modify your instance's `PYPI Packages` tab.
There you can add `astronomer-starship` as an entry by clicking `Edit`.
You can find more [detailed instructions here.](https://cloud.google.com/composer/docs/composer-2/install-python-dependencies)

:::cli
You can accomplish this easily with the `gcloud` CLI, in a terminal (make sure to change `[GCC_NAME]` below):
```sh
gcloud composer environments update [GCC_NAME] --update-pypi-package=astronomer-starship
```
:::

We will cover usage of the Starship migration utility later in this document

### Step 2: Create Astro Workspace

<Workspaces />

### Step 3: Create Astro Deployment

<Deployments />

## Migrate Airflow Metadata
In this step we will migrate Airflow Metadata with Starship from Source Environment

Additionally - you should utilize Starship to test connections as you migrate them.

### Step 4: Use Starship to Migrate Airflow Connections and Variables
<Usage />

## Migrate DAGs
### Step 5: Initialize new repository skeleton
<DAGs />

### Step 6: Copy core Airflow code
1. Edit `Dockerfile` to match Astro Runtime version to customer’s Source environment Airflow version
    <RuntimeVersionInfo />

    :::info
    The `Dockerfile` is the backing system that all of your Airflow components run in.
    You can customize that in a variety of ways, and might
    modify it to copy special things like certificates or keys to be available in your environment.

    You shouldn't need to modify your `Dockerfile` beyond this, for the purposes of this migration, but may in the future.
    :::
2. Add `requirements.txt` , as needed.
    :::cli
    You can do this with the CLI
    :::

3. Copy `/dags` folder from source control or blob storage
    :::cli
    You can do this with the CLI
    :::

### Step 7: Copy accessory Airflow code
Following recommended [project structure](https://docs.astronomer.io/learn/managing-airflow-code#project-structure):

- Copy `/plugins` folder from source control or blob storage, as needed
:::cli
You can do this with the CLI
:::