---
sidebar_label: 'Glossary'
title: 'Astro glossary'
id: astro-glossary
description: A quick reference for terms you'll encounter on Astro.
---
The following table contains definitions for all of the key terms and concepts you'll come across on Astro. For a glossary of Apache Airflow terms, see [Airflow glossary](https://docs.astronomer.io/learn/airflow-glossary).

| Term | Definition |
|------|-------------|
| API key | An API key is a unique key ID and secret grants programmatic access to a Deployment. API keys will soon be deprecated in favor of Deployment-level API tokens. |
| API token | An API token is an alphanumeric token that grants programmatic access to Astro. An API token can be scoped to a [Organization](organization-api-tokens.md) or [Workspace](workspace-api-tokens.md). |
| Astro | [Astro](https://www.astronomer.io/product/) is a SaaS application that runs fully-managed Apache Airflow environments in the cloud. Each Airflow environment runs in its own isolated Kubernetes namespace with the ability to scale up or down based on the number of tasks queued or running. |
| Astro alerts | [Astro alerts](alerts.md) are customizable Slack and Pagerduty alerts for Deployments running on Astro. Unlike Airflow alerts, Astro alerts are configured directly from the Cloud UI and require no changes to DAG code. |
| Astro CLI | The [Astro CLI](cli/overview.md) is an open source command line interface used to run Airflow locally and manage various resources on Astro. |
| Astro Hosted | [Astro Hosted](astro-architecture.md) is a version of Astro that's hosted and managed in Astronomer's cloud. |
| Astro Hybrid | [Astro Hybrid](hybrid-overview.md) is a version of Astro that's managed by Astronomer and hosted in the customer's cloud. |
| Astro project | An [Astro project](develop-project.md) contains the set of files necessary to run Airflow, including dedicated folders for the DAG files, plugins, and dependencies. A new Astro project can be created by running `astro dev init` with the Astro CLI. Each Deployment hosts exactly one Astro project. |
| Astro Runtime | [Astro Runtime](runtime-image-architecture.md) is an Astronomer-distributed Docker image for running Airflow. Compared to the Apache Airflow Docker image, Astro Runtime additionally includes smart default environment variables and packages, a security manager for RBAC, and expedited vulnerability fixes. |
| Astronomer Software | [Astronomer Software](https://docs.astronomer.io/software) is a product for running Apache Airflow in a private cloud or airgapped environment using Kubernetes. |
| Cell | A [cell](cloud-ide/quickstart.md#step-3-create-a-python-cell) is a UI-based abstraction of an Airflow task that serves as the building block for Astro Cloud IDE pipelines. It can either complete a unit of work or host an asset to be used by other cells. |
| Cloud UI | The Cloud UI is the user interface for accessing Astro. From the Cloud UI, users can manage Organizations, Workspaces, and Deployments, as well as develop pipelines in the Astro Cloud IDE. The Cloud UI is available at `https://cloud.astronomer.io`. |
| Cluster | An Astro cluster is a fully managed Kubernetes cluster that runs Deployments either in a customer's cloud or Astronomer's cloud. |
| Dedicated Cluster | A [dedicated cluster](create-dedicated-cluster.md) is a cluster type available on Astro Hosted. It is hosted on Astronomer's cloud and runs Deployments only from a single Organization.  |
| Control Plane | The Astro control plane is Astro's interface for managing Airflow environments running in the cloud. The Cloud UI or the Astro CLI is used to interact with the control plane. It provides end-to-end visibility, control, and management of users, teams, Workspaces, Deployments, metrics, and logs.|
| DAG Bundle Version | A DAG Bundle Version is a unique timestamp generated by the Astro CLI after a user completes a DAG-only deploy. This value exists only when [DAG-only deploys](deploy-code#deploy-dags-only) are enabled for a Deployment. |
| Data lineage | [Data lineage](data-lineage-concepts.md) is the concept of tracking and observing data flowing through a data pipeline. Data lineage can be used to understand data sources, troubleshoot run failures, manage personally identifiable information (PII), and ensure compliance with data regulations. Astro includes data lineage features in the Cloud UI.  |
| Data plane | The data plane, a component of [Astro Hybrid](hybrid-overview.md), is a single-tenant foundation in a customer's cloud for running multiple Airflow environments across clusters. A data plane can be multi-cloud and multi-region. |
| Deploy | A [deploy](deploy-code.md) is the process of pushing either an Astro project or DAG code to an Astro Deployment. |
| Deployment | An [Astro Deployment](create-deployment.md) is an Airflow environment that is powered by all core Airflow components, including a webserver, scheduler, triggerer, and one or more workers running in its own isolated namespace in a cluster. Astro users can deploy DAGs to a Deployment, and can have one or more Deployments within a Workspace. |
| Environment variable| An [environment variable](environment-variables.md) is a key-value pair that defines a configuration for a Deployment.  |
| High availability (HA) | [High availability (HA)](configure-deployment-resources#enable-high-availability) is a feature on Astro for ensuring that Deployments can run even in the event of an outage. On Astro Hosted, HA can be enabled or disabled per Deployment. |
| Namespace | A [namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) is a Kubernetes component which isolates Airflow environments within a Kubernetes cluster. Each Deployment uses a separate namespace to isolate resources. |
| Organization | An Organization is the highest management level on Astro. An Organization contains Workspaces, which are collections of Deployments, or Airflow environments, that are typically owned by a single team.  |
| Pipeline | A [pipeline](cloud-ide/quickstart.md#step-2-create-a-pipeline) is a notebook-style configuration for DAGs which is available in the Astro Cloud IDE. A pipeline can include traditional Airflow operators, as well as Python and SQL functions that are executed through the Astro Python SDK. |
| Standard cluster | A [standard cluster](resource-reference-hosted.md#standard-cluster-configurations) is a cluster type available on Astro Hosted. It is multi-tenant and runs Deployments from multiple Organizations. |
| Worker Node | A [worker node](resource-reference-hosted.md#worker-type) is a node used to run Airflow worker Pods, which are responsible for executing Airflow tasks in the Deployments. |
| Worker Node Pool | A [worker node pool](manage-hybrid-clusters#about-worker-node-pools) is a Kubernetes node pool that's used to run worker nodes of the same type on Astro Hybrid. Each worker node pool has a worker type and a maximum node count.  |
| Worker Queue | A [worker queue](configure-worker-queues.md) is a set of configurations that apply to a group of workers in a Deployment running the Celery executor. Within a worker queue, users can configure worker type, worker size, and autoscaling behavior.|
| Worker Type | The worker type defines the quantity of resources a celery worker can consume. On Astro Hosted, worker types are defined in terms of Astronomer units (A5, A10, A20). Each Ax type has a different configuration for memory, cpu and default number of concurrent tasks per celery worker. On Astro Hybrid, worker types are defined by the cloud node instance type that host celery workers and KubernetesPodOperator pods. |
| Workspace | [Workspaces](manage-workspaces.md) are collections of Deployments that can be accessed by a specific group of users. Workspaces can be used to group Deployments that share a business use case or environment trait. |