---
sidebar_label: 'Migrate to Astro from MWAA'
title: 'Migrating to Astro from MWAA'
id: migrate-mwaa
description: Get started on Astro by migrating your Airflow code from Amazon Managed Workflows for Apache Airflow (MWAA).
---

import Intro from './migration-partials/intro.md';
import Prerequisites from './migration-partials/prereqs.mdx';
import Requirements from './migration-partials/requirements.mdx';
import Starship from './migration-partials/starship.mdx';
import Usage from './migration-partials/starship-usage.mdx';
import Workspaces from './migration-partials/workspaces.md';
import Deployments from './migration-partials/deployments.mdx';
import DAGs from './migration-partials/directory-setup.md';
import RuntimeVersionInfo from './migration-partials/runtime-version-info.md'
import FinalStep from './migration-partials/final-step.mdx'
import TestLocally from './migration-partials/test-locally.md'
import Deploy from './migration-partials/deploy.md'
import Additional from './migration-partials/additional.md'
import WrapUp from './migration-partials/wrap-up.md'

This is where you'll find instructions for migrating to Astro from another managed Airflow environment. This guide will
cover migrating an Airflow Instance from [Amazon Managed Workflows for Apache Airflow (MWAA)](https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html)

<Intro />

## Prerequisites

<Prerequisites/>

### Requirements

<Requirements />

You can additionally utilize the `aws` CLI to expedite some steps in this guide.

## Prepare Source and Setup Astro Airflow

### Step 1: Install Astronomer Starship
<Starship />

#### Starship Compatability Matrix

| Source Airflow      | Starship Plugin | Starship Operator |
|---------------------|-----------------|-------------------|
| Airflow 1.x         | ❌               | ❌                 |
| MWAA v2.0.2         |                 | ✔️️               |
| MWAA v2.2.2         | ✔️️             |                   |
| MWAA v2.4.3         | ✔️️             |                   |

#### Installation
To install Starship to your MWAA instance, you'll need to edit the `requirements.txt` file in your S3 Bucket.
You can find more [detailed instructions here.](https://docs.aws.amazon.com/mwaa/latest/userguide/best-practices-dependencies.html#best-practices-dependencies-different-ways)

1. Download your existing `requirements.txt` file from S3
2. Add `astronomer-starship` on a new line in your `requirements.txt` file
3. Re-upload the file to your S3 bucket
4. Edit your Airflow Environment to refer to the new version of this file.

:::cli aws

You can accomplish this easily with the `aws` CLI, in a terminal:

Modify these values:
```sh
export MWAA_NAME="MWAA"
export MWAA_BUCKET="MWAA BUCKET"
```
then, in a terminal, run:
```shell
aws s3 cp "s3://$MWAA_BUCKET/requirements.txt" requirements.txt
echo 'astronomer-starship' >> requirements.txt
aws s3 cp requirements.txt "s3://$MWAA_BUCKET/requirements.txt"
aws mwaa update-environment "$MWAA_NAME" --requirements-s3-object-version="$(aws s3api head-object --bucket=$MWAA_BUCKET --key=requirements.txt --query="VersionId")"
```

:::

We will cover usage of the Starship migration utility later in this document

### Step 2: Create Astro Workspace

<Workspaces />


### Step 3: Create Astro Deployment

<Deployments />

## Migrate Airflow Metadata
In this step we will migrate Airflow Metadata with Starship from Source Environment

### Step 4: Use Starship to Migrate Airflow Connections and Variables
<Usage />

## Migrate DAGs
### Step 5: Initialize new repository skeleton
<DAGs />

### Step 6: Copy core Airflow code
1. Edit the `Dockerfile` 's Astro Runtime version to match the source Airflow version.
    **This must match the version of the Deployment you created in [Step 3](#step-3-create-astro-deployment)**.

    :::tip

    The Astro Runtime version is at the end of the line that begins with `FROM` -
    e.g. `FROM quay.io/astronomer/astro-runtime:1.2.3` would have a version of `1.2.3`

    The `Dockerfile` creates the backing environment that all of your Airflow components run in.
    You can customize that in a variety of ways, and might
    modify it to copy special things like certificates or keys to be available in your environment.

    You shouldn't need to modify your `Dockerfile` beyond the changes in this step, for the purposes of this migration, but may want to in the future.

    :::

2. Fill in your new `requirements.txt` file. You can do this by navigating to your S3 Bucket and downloading the file.

    :::cli aws

    You can easily copy this with the ` aws` CLI:
    ```shell
    aws s3 cp s3://[BUCKET]/requirements.txt requirements.txt
    ```
    Make sure to review the output after running this command

    :::

3. Copy your `/dags` folder from source control or S3 by navigating to either and downloading/moving the entire folder into your local Astro project.

    :::cli aws

    You can easily copy this with the ` aws` CLI:
    ```
     aws s3 cp --recursive s3://[BUCKET]/dags dags
    ```
    Make sure to review the output after running this command

    :::

### Step 7: Copy accessory Airflow code
Following the recommended [project structure](https://docs.astronomer.io/learn/managing-airflow-code#project-structure), we will move any files to our Astro project.

- If you have utilized the `/plugins` folder in your S3 Bucket, copy it from source control or the S3 Bucket to the local `/plugins` folder

:::cli aws

You can easily copy this with the ` aws` CLI:
```
aws s3 cp --recursive s3://[BUCKET]/plugins.zip plugins.zip
unzip plugins.zip
```
Make sure to review the output after running this command

:::

### Step 8: Configure Additional Components
<Additional />

### Step 9: Test locally and check for import errors
<TestLocally />

### Step 10: Deploy
<Deploy />

## Validate, Cut-over and Tune Process
<FinalStep />

## Wrapping up
<WrapUp />