---
sidebar_label: "Migrate to Astro from MWAA"
title: "Migrating to Astro from MWAA"
id: migrate-mwaa
description: Get started on Astro by migrating your Airflow code from Amazon Managed Workflows for Apache Airflow (MWAA).
---

import Intro from "./migration-partials/intro.md";
import Prerequisites from "./migration-partials/prereqs.mdx";
import Starship from "./migration-partials/starship.mdx";
import Usage from "./migration-partials/starship-usage.mdx";
import Workspaces from "./migration-partials/workspaces.mdx";
import Deployments from "./migration-partials/deployments.mdx";
import DAGs from "./migration-partials/directory-setup.mdx";
import FinalStep from "./migration-partials/final-step.mdx";
import TestLocally from "./migration-partials/test-locally.mdx";
import Deploy from "./migration-partials/deploy.mdx";
import Additional from "./migration-partials/additional.mdx";

This is where you'll find instructions for migrating to Astro from another managed Airflow environment. This guide will
cover migrating an Airflow Instance from [Amazon Managed Workflows for Apache Airflow (MWAA)](https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html)

<Intro />

## Prerequisites

<Prerequisites />

You can additionally utilize the `aws` CLI to expedite some steps in this guide.

## Step 1: Install Astronomer Starship

<Starship />

| Source Airflow environment | Starship plugin | Starship operator |
| -------------------------- | --------------- | ----------------- |
| Airflow 1.x                | ❌              | ❌                |
| MWAA v2.0.2                |                 | ✔️️                 |
| MWAA v2.2.2                | ✔️️               |                   |
| MWAA v2.4.3                | ✔️️               |                   |

To install Starship to your MWAA instance as a plugin:

1. Download your existing `requirements.txt` file for your source Airflow environment from S3. See [AWS documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/best-practices-dependencies.html#best-practices-dependencies-different-ways).
2. Add `astronomer-starship` on a new line to your `requirements.txt` file.
3. Re-upload the file to your S3 bucket.
4. Edit your Airflow environment to refer to the new version of this file.

:::tip

You can alternatively complete this installation with the `aws` CLI. 

1. Run the following commands to set environment variables on your local machine:

    ```sh
    export MWAA_NAME="MWAA"
    export MWAA_BUCKET="MWAA BUCKET"
    ```

2. Run the following commands to install Starship:

    ```shell
    aws s3 cp "s3://$MWAA_BUCKET/requirements.txt" requirements.txt
    echo 'astronomer-starship' >> requirements.txt
    aws s3 cp requirements.txt "s3://$MWAA_BUCKET/requirements.txt"
    aws mwaa update-environment "$MWAA_NAME" --requirements-s3-object-version="$(aws s3api head-object --bucket=$MWAA_BUCKET --key=requirements.txt --query="VersionId")"
    ```

:::

## Step 2: Create an Astro Workspace

<Workspaces />

## Step 3: Create an Astro Deployment

<Deployments />

## Step 4: Use Starship to Migrate Airflow Connections and Variables

<Usage />

## Step 5: Initialize new repository skeleton

<DAGs />

### Step 6: Copy core Airflow code
1. Edit the `Dockerfile` 's Astro Runtime version to match the source Airflow version.
    **This must match the version of the Deployment you created in [Step 3](#step-3-create-astro-deployment)**.

    :::tip

    The Astro Runtime version is at the end of the line that begins with `FROM` -
    e.g. `FROM quay.io/astronomer/astro-runtime:1.2.3` would have a version of `1.2.3`

   :::info

    You shouldn't need to modify your `Dockerfile` beyond the changes in this step, for the purposes of this migration, but may want to in the future.

   You shouldn't need to modify your `Dockerfile` beyond this, for the purposes of this migration, but may in the future.

   :::

2. Fill in your new `requirements.txt` file. You can do this by navigating to your S3 Bucket and downloading the file.

    :::cli aws

   You can easily copy this with the ` aws` CLI:

   ```shell
   aws s3 cp s3://[BUCKET]/requirements.txt requirements.txt
   ```

   Make sure to review the output after running this command

   :::

3. Copy your `/dags` folder from source control or S3 by navigating to either and downloading/moving the entire folder into your local Astro project.

    :::cli aws

   You can easily copy this with the ` aws` CLI:

   ```
    aws s3 cp --recursive s3://[BUCKET]/dags dags
   ```

   Make sure to review the output after running this command

   :::

## Step 7: Copy accessory Airflow code

Following the recommended [project structure](https://docs.astronomer.io/learn/managing-airflow-code#project-structure), we will move any files to our Astro project.

- If you have utilized the `/plugins` folder in your S3 Bucket, copy it from source control or the S3 Bucket to the local `/plugins` folder

:::cli aws

You can easily copy this with the ` aws` CLI:

```
aws s3 cp --recursive s3://[BUCKET]/plugins.zip plugins.zip
unzip plugins.zip
```

Make sure to review the output after running this command

:::

## Step 8: Configure Additional Components

<Additional />

## Step 9: Test locally and check for import errors

<TestLocally />

## Step 10: Deploy

<Deploy />

## Validate, Cut-over and Tune Process

<FinalStep />

## Wrapping up

<WrapUp />
